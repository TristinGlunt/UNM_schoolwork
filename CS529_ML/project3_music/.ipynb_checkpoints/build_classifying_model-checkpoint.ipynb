{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 'jupyter notebook' from Conda Terminal before beginning to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17406735427828061586\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4952306483\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9356040453312676462\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "Tensorflow:  1.11.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print('Tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train_split_2.dat\")\n",
    "y_train = np.load(\"y_train_split_2.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data and reformat for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "# reshape so in form for CNN-Keras\n",
    "X_train = X_train.reshape(X_train.shape[0], 174, 124, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 174, 124, 1)\n",
      "(13500, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation x train set:(2700, 174, 124, 1)\n",
      "X train set:(10800, 174, 124, 1)\n",
      "Validation y train set:(2700, 10)\n",
      "Y train set:(10800, 10)\n"
     ]
    }
   ],
   "source": [
    "training_set_size = int(X_train.shape[0] * .80)\n",
    "\n",
    "# split data into validation set\n",
    "X_train_validation = X_train[training_set_size:, :,:,:]\n",
    "y_train_validation = y_train[training_set_size:, :]\n",
    "y_train = y_train[:training_set_size,:]\n",
    "X_train = X_train[:training_set_size, :, :, :]\n",
    "print(\"Validation x train set:\" + str(X_train_validation.shape))\n",
    "print(\"X train set:\" + str(X_train.shape))\n",
    "print(\"Validation y train set:\" + str(y_train_validation.shape))\n",
    "print(\"Y train set:\" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 like network from Andrew Ng's course on Coursera\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (7,7), strides=(1,1), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(32, (7,7), strides=(1,1)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(64, (7, 7), strides=(1,1)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (7, 7), strides=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10800 samples, validate on 2700 samples\n",
      "Epoch 1/50\n",
      "10800/10800 [==============================] - 28s 3ms/step - loss: 2.4814 - acc: 0.1890 - val_loss: 11.4214 - val_acc: 0.1859\n",
      "Epoch 2/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 2.0943 - acc: 0.2674 - val_loss: 1.8461 - val_acc: 0.3241\n",
      "Epoch 3/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.8955 - acc: 0.3180 - val_loss: 1.7988 - val_acc: 0.3100\n",
      "Epoch 4/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.8105 - acc: 0.3417 - val_loss: 4.2132 - val_acc: 0.1030\n",
      "Epoch 5/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.7225 - acc: 0.3745 - val_loss: 1.5453 - val_acc: 0.4341\n",
      "Epoch 6/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.6709 - acc: 0.3914 - val_loss: 1.8053 - val_acc: 0.3689\n",
      "Epoch 7/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.6154 - acc: 0.4110 - val_loss: 1.5399 - val_acc: 0.4785\n",
      "Epoch 8/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.5693 - acc: 0.4327 - val_loss: 2.6011 - val_acc: 0.2811\n",
      "Epoch 9/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.5232 - acc: 0.4559 - val_loss: 1.8175 - val_acc: 0.3852\n",
      "Epoch 10/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.4590 - acc: 0.4817 - val_loss: 1.3568 - val_acc: 0.5304\n",
      "Epoch 11/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.4324 - acc: 0.4906 - val_loss: 1.7564 - val_acc: 0.3796\n",
      "Epoch 12/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.4138 - acc: 0.5017 - val_loss: 1.6159 - val_acc: 0.3841\n",
      "Epoch 13/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.3742 - acc: 0.5170 - val_loss: 1.4272 - val_acc: 0.4978\n",
      "Epoch 14/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.3375 - acc: 0.5302 - val_loss: 1.6142 - val_acc: 0.4278\n",
      "Epoch 15/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.2885 - acc: 0.5472 - val_loss: 2.6122 - val_acc: 0.2126\n",
      "Epoch 16/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.2759 - acc: 0.5473 - val_loss: 1.1877 - val_acc: 0.6007\n",
      "Epoch 17/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.2355 - acc: 0.5693 - val_loss: 1.4441 - val_acc: 0.4693s: 1.237\n",
      "Epoch 18/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.2115 - acc: 0.5832 - val_loss: 1.0761 - val_acc: 0.6322\n",
      "Epoch 19/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.1949 - acc: 0.5809 - val_loss: 1.3410 - val_acc: 0.4959\n",
      "Epoch 20/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.1677 - acc: 0.5923 - val_loss: 2.9356 - val_acc: 0.2426\n",
      "Epoch 21/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.1562 - acc: 0.5988 - val_loss: 2.3712 - val_acc: 0.2563\n",
      "Epoch 22/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.1243 - acc: 0.6078 - val_loss: 1.5179 - val_acc: 0.5189\n",
      "Epoch 23/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.1003 - acc: 0.6143 - val_loss: 1.7580 - val_acc: 0.3396\n",
      "Epoch 24/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.0814 - acc: 0.6221 - val_loss: 1.2264 - val_acc: 0.5681\n",
      "Epoch 25/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.0798 - acc: 0.6229 - val_loss: 1.4095 - val_acc: 0.5241\n",
      "Epoch 26/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.0532 - acc: 0.6323 - val_loss: 1.3861 - val_acc: 0.4974\n",
      "Epoch 27/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.0192 - acc: 0.6462 - val_loss: 1.2685 - val_acc: 0.5585\n",
      "Epoch 28/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 1.0030 - acc: 0.6494 - val_loss: 0.9785 - val_acc: 0.6493\n",
      "Epoch 29/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.9965 - acc: 0.6468 - val_loss: 2.1787 - val_acc: 0.3752\n",
      "Epoch 30/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.9629 - acc: 0.6643 - val_loss: 0.9843 - val_acc: 0.6370\n",
      "Epoch 31/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.9671 - acc: 0.6644 - val_loss: 0.9524 - val_acc: 0.6767\n",
      "Epoch 32/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.9458 - acc: 0.6713 - val_loss: 1.1254 - val_acc: 0.6000\n",
      "Epoch 33/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.9357 - acc: 0.6800 - val_loss: 0.9743 - val_acc: 0.6578\n",
      "Epoch 34/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.9317 - acc: 0.6733 - val_loss: 0.9156 - val_acc: 0.6841\n",
      "Epoch 35/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.9046 - acc: 0.6853 - val_loss: 2.2871 - val_acc: 0.3270\n",
      "Epoch 36/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.8949 - acc: 0.6861 - val_loss: 0.9591 - val_acc: 0.6800\n",
      "Epoch 37/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.8771 - acc: 0.6879 - val_loss: 3.4954 - val_acc: 0.3115\n",
      "Epoch 38/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.8667 - acc: 0.6908 - val_loss: 0.9080 - val_acc: 0.6841\n",
      "Epoch 39/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.8704 - acc: 0.6935 - val_loss: 2.1043 - val_acc: 0.4633\n",
      "Epoch 40/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.8530 - acc: 0.7003 - val_loss: 1.7942 - val_acc: 0.4474\n",
      "Epoch 41/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.8413 - acc: 0.6995 - val_loss: 0.9878 - val_acc: 0.6544\n",
      "Epoch 42/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.8365 - acc: 0.7001 - val_loss: 1.1258 - val_acc: 0.6226\n",
      "Epoch 43/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.8080 - acc: 0.7130 - val_loss: 1.8011 - val_acc: 0.5430\n",
      "Epoch 44/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.7966 - acc: 0.7156 - val_loss: 1.6649 - val_acc: 0.5252\n",
      "Epoch 45/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.7864 - acc: 0.7214 - val_loss: 1.4595 - val_acc: 0.5674\n",
      "Epoch 46/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.8102 - acc: 0.7118 - val_loss: 1.1646 - val_acc: 0.6181\n",
      "Epoch 47/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.7496 - acc: 0.7317 - val_loss: 0.9383 - val_acc: 0.6863\n",
      "Epoch 48/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.7664 - acc: 0.7247 - val_loss: 1.3820 - val_acc: 0.6130\n",
      "Epoch 49/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.7532 - acc: 0.7308 - val_loss: 1.2003 - val_acc: 0.6000\n",
      "Epoch 50/50\n",
      "10800/10800 [==============================] - 24s 2ms/step - loss: 0.7409 - acc: 0.7354 - val_loss: 1.5411 - val_acc: 0.5730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18c11945f98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_2splits_50epochs_highLR\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/trained_music_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step\n",
      "[3.419465198516846, 0.5800000071525574]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train_validation, y_train_validation, batch_size=32, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = Sequential()\n",
    "\n",
    "ann_model.add(Flatten())\n",
    "ann_model.add(Dense(512, activation = 'relu', input_shape = X_input.shape[1:]))\n",
    "ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(256), activation = 'relu')\n",
    "ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(128), activation = 'relu')\n",
    "ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(64), activation = 'relu')\n",
    "ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(10), activation = 'softmax')\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_2splits_50epochs_highLR\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
    "\n",
    "ann_model.compile(adam, 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(X_train, y_train, batch_size=32, epochs=50 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
